---
title: "Investigating Persuasiveness in Large Language Models"
collection: publications
permalink: /publication/2010-10-01-paper-title-number-2
excerpt: 'This paper is about the number 2. The number 3 is left for future work.'
date: 2010-10-01
venue: 'Princeton University ProQuest Dissertations Publishing'
paperurl: 'http://academicpages.github.io/files/paper2.pdf'
citation: 'Your Name, You. (2010). &quot;Paper Title Number 2.&quot; <i>Journal 1</i>. 1(2).'
---
While the rate of progress and innovation in Artificial intelligence (AI) has many potential benefits,
the potential for accidental deleterious effects cannot be overemphasized [6]. It has been empirically
demonstrated that large language models (LLMs) can learn to perform a wide range of natural
language processing (NLP) tasks in a self-supervised setting [23]. However, these models might
unintentionally produce convincing arguments for false statements.

[Download paper here](https://drive.google.com/file/d/198B-qd--Z1NGEOXJ4hDWvt8rAkGTSi-u/view?usp=sharing)

Recommended citation: P. O. Ekpo (2023). "Investigating Persuasiveness in Large Language Models." <i>Princeton University ProQuest Dissertations Publishing</i>. 1(2).